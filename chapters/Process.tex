\thispagestyle{plain}
\section{Hardware}
The hardware involved in this research was one Raspberry pi 2.  The Raspberry pi 2 consists of a quad core ARM Cortex A7 processor clocked at 900mhz coupled to a Broadcom VideoCore IV 3D graphics processor.
\section{Data}
Several Stereo vision datasets were used in the process of this research.  In addition to datasets generated specifically for this research, the XXX and XXX datasets were also used for sanity checking.
\section{Process}
The first step in this research was to compile the OpenCV library on the Raspberry Pi 2.  Once this was complete the camera calibration described earlier was performed using the StereoCalibrate() function built into OpenCV.  The results of this function is a camera matrix describing the fundamental parameters of each camera along with a set of distortion coefficients for each of the cameras.  Additionally, this function outputs a rotation matrix from camera1 to camera2, and a translation vector between the same.  All of these parameters were then passed to the stereoRectify() function which was also built into OpenCV.  The stereoRectify() function returns a rotation and projection matrix for each of the camera that reprojects both images onto a shared plane.  This is important because, as mentioned before, it allows us to turn a 2-Dimensional search for correspondence into a 1-Dimensional search along the scanline of an image.  It is at this point that the processes diverge.  For the baseline cpu measurement, these matrices were passed into the initUndistortRectifyMap() function and then into the remap() function to rectify the images.  A Stereo Block Matching (SBM) object was then created on the images and used to calculate a depth map.  All of these functions were purely CPU functions, and made little to no use of threading.  For my improvements to this project, once I had the rotation and projection matrices, An OpenGL Vertex Array Object was generated containing one vertex per pixel in the source image.  This VAO was then passed through a shader pair which applied the rotation and projection to each pixel in the image.  The result of this shader pair was written to an OpenGL Framebuffer Object (FBO).  This allows us to treat the resulting image as a texture, which we then sampled in a second shader pair.  In the second shader pair, we implement the Stereo Block Matching Algorithm, meaning that for every pixel in our resulting depthmap we sample an NxN (Where N is odd) square of pixels surrounding that coordinate in the left texture, then for each x value in the right image that is lower than that pixel coordinate, we sample another NxN square, and calculate the difference in values between the corresponding pixels.  These differences are then squared and summed across all values sampled.  The sample with the lowest Sum of Squared Differences is then selected and the disparity is calculated using the difference between the x values of the corresponding values.