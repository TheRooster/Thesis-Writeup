Generating a depth map from a pair of stereo cameras involves 3 main steps.  First, each camera must be calibrated, a process that removes distortion and calculates several parameters useful in the later steps.  Second, the cameras must be rectified, which translates, rotates and skews the images such that the cameras appear to exist on the same plane.  Lastly, the images are then processed using a stereo block matching algorithm to find corresponding areas in each of the images.  From this correspondence, depth values can be estimated and written into a depth map.

\section{Calibration}
In order to calibrate a single camera, several things must be calculated.  These values are referred to as the Intrinsic and Extrinsic parameters of the camera.  The Intrinsic parameters of a camera relate the image coordinates to the Idealized image coordinates and correct for the "Skewness" of the image. The Extrinsic parameters of a camera calculate the cameras position with respect to some general frame of reference.


\subsection{Intrinsic Parameters}
IMAGE 1 GOES HERE

Consider the image above, where x and y refer to a single position in "world space", \^{u} and \^{v} refer to that same position on the normalized image plane, and u and v refer to that position on the physical image plane.  This is what is known as the "Pinhole Camera Model", as all points on the physical image plane can be thought of as having been projected through a point of size 0 existing somewhere in worldspace.  One thing to note here is that \^{u} and \^{v} can be calculated by $x/z$ and $y/z$ respectively.
\subsubsection{Skew}
The first calculation of the intrinsic camera parameters deals with the "skew" of the image.  As can be observed in IMAGE2, the physical image plane may not be a perfect rectangle.  Due to defects in craftmanship and/or wear and tear on the camera, the physical image plane may be a parallelogram.  In this case, we can relate x and y to u and v via the calculation of $u=\hat{u}-\frac{y}{z} * \frac{sin  \theta }{ cos \theta} * f$ and $v=\hat{v}*\frac{1}{sin \theta} * f$ respectively, where $\theta$ is the angle between the perpendicular axis and the observed axis and $f$ is the focal length of the camera.

In addition to the physical image plane not being rectangular, it may also not be aligned with the idealized image plane.  To
account for this we introduce 2 new values $u\subset{0}$ and $v\subset{0}$ to account for this misalignment.  This means that our 
calculation becomes $u=\hat{u}-\frac{y}{z} * cot \theta * f + u\subset{0}$ and $v=\hat{v} * \frac{1}{sin \theta} * f + 
v\subset{0}$. By substituting $\alpha$ and $\beta$ for the horizontal and vertical focal length we can rewrite these formulas as a 
multiplication of homogenous coordinates like so $\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha & -\alpha cot\theta & u_{0} \\ 0 & \frac{\beta}{sin\theta} & v_{0} \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix}\hat{u} \\ \hat{v}\\ 1\end{bmatrix}$.  Now, if we remember that $u$ and $v$ refer to points on the actual image and $\hat{u}$ and $\hat{v}$ refer to that same point on the normalized image plane, then the matrix $\begin{bmatrix} \alpha & -\alpha cot\theta & u_{0} \\ 0 & \frac{\beta}{sin\theta} & v_{0} \\ 0 & 0 & 1 \end{bmatrix}$ can be interpreted as a transformation matrix between points on the normalized image plane into points on the actual image.  We will refer to this matrix as $K$ from here on out.

\subsection{Extrinsic Parameters}
\section{Rectification}

\section{Correspondence}